\chapter{Untersuchung des Verfahrens}\label{ch:results}

\section{Implementierung}
Es wurden im wesentlichen $3$ Programme implementiert.  \\
Das Programm \textit{onestep} führt einen Schritt der Faktorisierung einer Zahl durch, bildet also Algorithmus~\ref{alg:factorize} ab. \\
Mit dem Programm \textit{factorize} kann die komplette Faktorisierung einer Zahl berechnet werden. Es führt also den Algorithmus~\ref{alg:factorize} an der Zahl $N$ aus. Anschließend wird durch vergleich mit einer Liste vom Primzahlen überprüft, ob die erhaltenen Faktoren prim sind. Ist dies nicht der Fall wird der Algorithmus auf die entsprechenden Faktoren angewendet, bis die komplette Zerlegung ermittelt wurde. Dieses Programm wählt den Wert der Boltzmann-Konstanten immer automatisch (siehe Abschnitt~\ref{sec:kbguess}), weil sie für die entsprechenden Zerlegungsschritte angepasst werden muss.\\
Das Programm \textit{semiprime} bekommt zwei Primfaktoren $A$ und $B$ übergeben und berechnet das Produkt $N=A\cdot B$, welches folglich eine Semiprimzahl ist. Die $a, a_1, b, b_1$ sind durch die übergebenen Zahlen bereits bekannt. Dann werden $N_a$ Annealing-Schritte durchgeführt mit jeweils $N_c$ Konfigurationen/Metropolis-Schritten. Im Prinzip wird hier nur der Schleifendurchlauf aus Algorithmus~\ref{alg:factorize} durchgeführt, der zu einem Ergebnis führen könnte. Mit diesem Programm soll hauptsächlich der Einfluss der Wahl der Boltzmann-Konstanten auf das Verfahren untersucht werden. \\
Beim Programmdurchlauf werden jeweils die Laufzeit, der Erfolgsrate und die Anzahl der benötigten Metropolis-Schritte. \\
Die angewendete Methode ist nicht-deterministisch und führt somit nicht immer zum gewünschten Ergebnis. Da die Probe bei allen $3$ Programmen effizient durchführbar ist, wird bei jedem Durchlauf der Erfolg oder Misserfolg gespeichert. Daraus kann die Erfolgsrate durch Division der Anzahl der erfolgreichen Versuche durch die Anzahl der Aufrufe berechnet werden. \\
Beim Programm \textit{semiprime} ist die Anzahl der Schritte im Falle eines Misserfolgs $N_a\cdot N_c$ ansonsten eine kleinere Anzahl. Beim Programm \textit{onestep} ist die Anzahl der Schritte bei Misserfolg durch Gl.\eqref{eq:runtime-theo-opt} gegeben.\\
Für die Implementierung des Verfahrens wurde die Programmiersprache C++ verwendet. Alle Programme bieten die Möglichkeit zur Verwendung von Threads, also der parallelen Programmausführung, vgl. Abschnitt~\ref{sec:parallel}. Dabei kommt die Thread-Bibliothek aus dem aktuellen C++11 Standard zum Einsatz. \\
Zur Auswertung und für die grafische Darstellung wurde die Programmiersprache Python mit den Paketen numpy, scipy und matplotlib verwendet. \\ 

\section{\texorpdfstring{Abschätzung von $\bm{k_\mathrm{B}}$}{Abschätzung von kB}}\label{sec:kbguess}
Bei allen Untersuchungen wurde hier als zu maximierende Kostenfunktion
\begin{equation*}
		E\left(A,B,N\right)=\sum\limits_{i=1}^n\begin{cases}
    i^2 & \mathrm{falls}\:{\left\{A\cdot B\right\}}_i={\left\{N\right\}}_i \\
	0 & \mathrm{sonst}
  \end{cases}
\end{equation*}
gewählt. Der maximale Wert dieser Funktion ist eine quadratische Pyramidalzahl~\parencite{oeis}, also
\begin{equation*}
		E_{\mathrm{\max}}\left(n\right)=\sum\limits_{i=1}^n i^2=\frac{1}{3}n^3+\frac{1}{2}n^2+\frac{1}{6}n,\label{eq:kbguess}
\end{equation*}
sodass die Energie mit $\mathcal{O}\left(n^3\right)$ skaliert. \\
Es ist wichtig $k_\mathrm{B}$ geeignet zu wählen, weil dieser Paramter die Wahrscheinlichkeit bestimmt, mit der der Metroplisalgorithmus energetisch ungünstigere Konfigurationen akzeptiert. Kennt man für ein $\tilde{n}$ einen guten Wert $\tilde{k}_\mathrm{B}$, so kann man nach
\begin{equation*}
		k_\mathrm{B}=\frac{E_{\mathrm{\max}}\left(n\right)}{E_{\mathrm{\max}}\left(\tilde{n}\right)}\tilde{k}_\mathrm{B}
\end{equation*}
eine Abschätzung bei beliebiger Zahlenlänge $n$ für die zu wählende Boltzmann-Konstante treffen. \\
Das Experimentieren mit verschiedenen Werten hat gezeigt, dass bei $n=33$ eine Boltzmannkonstante $\tilde{k}_\mathrm{B}\approx 8^3=512$ zu guten Erfolgsraten führt. \\
Außerdem wurde das Programm \textit{semiprime} verwendet, um gezielt nach einem optimalen Wert für $k_B$ zu suchen. Dabei wurden zwei Primzahlen $A=66889$ und $B=104723$ gewählt, welche die Semiprimzahl $N=A\cdot B=7004816747$ mit $n=33$, ergeben und das Programm für verschiedene Werte $1^3\leq k_\mathrm{B}\leq 16^3$ aufgerufen. Jeder Durchlauf wurde dabei $4800$-mal wiederholt. Als Parameter wurden $N_a=1000$, $N_c=80000$ und $F_c=0.997$ gewählt. \\
Es wurde noch eine zweite Reihe von Simulationen mit den selben Parametern durchgeführt, allerdings mit Werten $4^3\leq k_\mathrm{B} \leq 28^3$. \\
Die Erfolgsrate wurde ermittelt, indem für jeden Wert $k_\mathrm{B}$ der Anteil der efolgreichen Programmdurchläufe berechnet wurden. Die Laufzeiten wurden analog, d.h.\ über Mittelung über alle Laufzeiten, also unabhängig davon, ob diese zu erfolgreichen Durchläufen gehören, bestimmt.\\
Die ermittelte Erfolsgrate bzw.\ die Programmlaufzeiten sind in Abb.~\ref{fig:kbguess-success} bzw.~\ref{fig:kbguess-runtime} grafisch dargestellt. \\
Es ist deutlich erkennbar, dass ein zu niedriger Wert von $k_\mathrm{B}$ zu Erfolgsraten nahe $0$ führt, also nur die wenigsten Programmaufrufe die Primfaktoren $A,B$ finden. Für den Erfahrungswert $k_\mathrm{B}\approx 8^3$ ergibt sich bereits eine Erfolgsrate von $\approx30\%$. Besser scheint es jedoch beispielsweise $k_\mathrm{B}=17^3$ oder auch größer zu wählen, was hier einer Erfolgsrate von $>\SI{45}{\percent}$ entspricht. \\
Dieses Verhalten spiegelt sich auch in der Programmlaufzeit wieder. Zu Beginn ist diese nahezu konstant, da kaum Durchläufe die gesuchten Faktoren finden und dadurch $N_c\cdot N_a$ Schritte durchlaufen werden. Mit steigendem $k_\mathrm{B}$ sinkt die Laufzeit des Programmes. Dies spiegelt die zunehmende Erfolgsrate wieder. Wenn mehr Durchläufe erfolgreich sind, führen weniger Programmaufrufe dazu, dass der gesamte Parameterbereich durchlaufen werden muss. Dies passiert bei den nicht erfolgreichen Durchläufen. \\
Betrachtet man die Akzeptanzwahrscheinlichkeit, so kann man dieses Verhalten erklären. Ein zu kleines $k_\mathrm{B}$ führt dazu, dass so gut wie keine ungünstigen Konfigurationen akzeptiert werden. Dies wiederspricht der grundsätlichen Idee hinter dem Metropolisalgorithmus, da auch schlechtere Konfigurationen teilweise akzeptiert werden müssen, damit das Verfahren in kein lokales Extremum läuft. Es ist auch zu erwarten, dass $k_\mathrm{B}$ nicht zu groß gewählt werden sollte, weil dies dazu führen würde, dass die Akzeptanzwahrscheinlichkeit für schlechtere Zahlen $A, B$ sehr hoch ist. Der Algorithmus würde sich hier nicht der gesuchten Lösung nähern, sondern die Zahlen $A, B$ beliebig ändern. \\
Es wäre also günstiger gewesen in der Formel~\eqref{eq:kbguess} beispielsweise $\tilde{k}_\mathrm{B}=17^3=4913$ für $\tilde{n}=33$ zu wählen. In den nachfolgenden Untersuchungen konnte dies jedoch nicht berücksichtigt werden, da diese Erkenntnis erst sehr spät gemacht wurde. In allen weiteren Simulationen wurde $\tilde{k}_\mathrm{B}=8^3=512$ gesetzt, um automatisch Werte der Boltzmann-Konstanten in Abhängigkeit der Länge $n$ der zu faktorisierenden Zahl zu ermitteln.
\begin{figure}[ht]
		\centering
		\includegraphics[height=0.35\textheight]{plot/kbguess/success.pdf}
		\caption{Erfolgsrate bei der Suche nach einem optimalen Wert für $k_\mathrm{B}$}\label{fig:kbguess-success}
\end{figure}
\begin{figure}[ht]
		\centering
		\includegraphics[height=0.35\textheight]{plot/kbguess/time.pdf}
		\caption{Laufzeiten bei der Suche nach einem optimalen Wert für $k_\mathrm{B}$}\label{fig:kbguess-runtime}
\end{figure}

\section{Parallelisierbarkeit}\label{sec:parallel}
Betrachtet man Algorithmus~\ref{alg:factorize}, so erkennt man, dass dieses Verfahren zur Primfaktorzerlegung Potential zur Parallelisierung bietet. So kann das Annealing für jedes Tupel $\left(a,a_1,b,b_1\right)$ unabhängig ausgeführt werden. Man generiert für jedes Tupel neue Anfangskonfigurationen $A$ und $B$ und führt dann jeweils das Annealing aus. Dies kann dann auf verschiedenen Prozessorkernen oder Rechnern erfolgen. Dadurch ist eine enorme Leistungssteigerung zu erwarten.\\
Dieses Vorgehen unterscheidet sich jedoch leicht von Algorithmus~\ref{alg:factorize}. Dort wird für jedes Tupel $\left(a,a_1\right)$ eine Anfangskonfiguration $A$ generiert und dann über alle Werte $\left(b,b_1\right)$ iteriert. Dabei werden dann Anfangskonfigurationen $B$ erzeugt. Da $A$ jedoch zufällig gewählt wird und innerhalb der Schleifen zufällige modifiziert wird, kann für jedes Tupel $\left(a,a_1,b,b_1\right)$ eine neues $A$ zufällig generiert werden. \\
Die Implementierung der Programme erlaubt es, eine beliebige Anzahl von Threads festzulegen, auf die die Tupel $\left(a,a_1,b,b_1\right)$ gleichmäßig verteilt werden. So wurden bereits die Simulationen in Abschnitt~\ref{sec:kbguess} mit $8$ Threads ausgeführt, genauso wie alle späteren Simulationen mit der Ausnahme der in diesem Abschnitt zu findenden. \\
Es soll durch Aufruf des Programms \textit{onestep} mit verschiedenen Anzahlen von Threads untersucht werden, wie effizient die Parallelisierung gelungen ist. Theoretisch halbiert sich die Laufzeit, wenn man die Anzahl der Threads verdoppelt. Dieses Vorgehen führt jedoch zu einem gewissen Verwaltungsaufwand beim erstellen der Threads, so dass die Parallelisierungseffizienz nicht bei $\SI{100}{\percent}$ liegen wird.\\
Der Begriff Parallelisierungseffizienz bezeichnet hier den Quotienten $\tau_1/\left(i\tau_i\right)$. Dabei ist $i$ die Anzahl der Threads und $\tau_j$ die Laufzeit des Programs mit $j$ Threads. Es wird also die Laufzeit des Programmes mit mehreren Threads mit dem seriellen Programm gemäß Algorithmus~\ref{alg:factorize} verglichen.
\begin{figure}[ht]
		\centering
		\includegraphics[height=0.35\textheight]{plot/dummy/dummy.pdf}
		\caption{Ein schmucker Platzhalter}
\end{figure}

\section{Analyse eines einzelnen Zerlegungsschrittes}
Mit dem Programm \textit{onestep} wurden einzelne Zerlegungsschritte untersucht und dafür zunächst zwei Sätze von Zahlen gewählt. Zum einen wurden manuell für $n\in\left\{6,8,\dots,24\right\}$ je $10$ Semiprimzahlen konstruiert, sowie die drei Möglichen für $n=4$. Der andere Satz von Zahlen besteht aus beliebigen Zahlen, wobei für jedes $n\in\left\{8,9,\dots,32\right\}$ jeweils $15$ solcher Zahlen zufällig ausgesucht wurden. Die Boltzmann-Konstante wurde dabei wie in Abschnitt~\ref{sec:kbguess} beschrieben automatisch gewählt.\\
Die Parameter waren $N_a=500$, $N_c=1000$ und $F_c=0.997$. Bei den Semiprimzahlen wurde jede Zerlegung $20$-mal durchgeführt, bei den beliebigen Zahlen auf Grund des größeren Datensatzes nur $10$-mal. \\
Für jedes $n$ wurde die Erfolgsrate bestimmt. Dabei wurden die Anzahl der erfolgreichen Zerlegungen der Zahlen der Länge $n$ aufsummiert und durch die Gesamtzahl aller Zerlegungen dividiert. Die Laufzeit wurde auf zwei Arten bestimmt. Zum einen wurden Analog zur Erfolgsrate einfach alle Laufzeiten zu jedem $n$ gemittelt, zum anderen wurde nur über die erfolgreichen Durchläufe gemittelt. Der Grund dafür ist, dass beide Mittelungen interessant sein können. Die eine gibt an, welche Zeit das Programm im Mittel benötigt, bis es unabhängig vom Ergebnis beendet wird, die andere, wie lange die erfolgreichen Zerlegungen im Mittel brauchen. \\
Die dabei ermittelten Erfolgsraten wurden in Abb.~\ref{fig:runtime-success} und Abb.~\ref{fig:runtime2-success} dargestellt. \\
In beiden Fällen erkennt man, dass die Erfolgsrate mit zunehmendem $n$ merklich abnimmt. Dies liegt daran, dass $N_a$ und $N_c$ für alle $N$ gleich belassen wurden. Der Bereich in dem $\left(a,a_1,b,b_1\right)$ liegen können wächst jedoch mit zunehmendem $n$, genauso wie die oberen Grenzen für $a$ und $b$. Für große $a$ und $b$ gibt es viel mehr mögliche Zahlen $A, B$ mit gegebenen $a_1$ und $b_1$. Dies bedeutet, dass bei großen $n$ ein geringerer Anteil der möglichen Zahlen $A$ und $B$ durchlaufen wird als bei kleinen $n$, somit sinkt auch die Wahrscheinlichkeit, die Faktoren zu finden.
\begin{figure}[ht]
		\centering
		\includegraphics[height=0.35\textheight]{plot/runtime/success.pdf}
		\caption{Erfolgsrate bei der Zerlegung von Semiprimzahlen}\label{fig:runtime-success}
\end{figure}
\begin{figure}[ht]
		\centering
		\includegraphics[height=0.35\textheight]{plot/runtime2/success.pdf}
		\caption{Erfolgsrate bei der Zerlegung von beliebigen Zahlen}\label{fig:runtime2-success}
\end{figure}
\begin{figure}[ht]
		\centering
		\includegraphics[height=0.35\textheight]{plot/runtime/time.pdf}
		\caption{Laufzeiten bei der Zerlegung von Semiprimzahlen}\label{fig:runtime-runtime}
\end{figure}
\begin{figure}[ht]
		\centering
		\includegraphics[height=0.35\textheight]{plot/runtime2/time.pdf}
		\caption{Laufzeiten bei der Zerlegung von beliebigen Zahlen}\label{fig:runtime2-runtime}
\end{figure}

\section{Laufzeitverhalten bei kompletter Zerlegung}
Mit dem Programm \textit{factorize} wurde für $n=8,9,\dots,32$ die Zerlegung von Zahlen in alle ihre Primfaktoren untersucht. Dazu wurden für jedes $n$ zufällig $5$ Zahlen gezogen und jede davon $10$-mal zerlegt. Als Parameter wurden $N_a=1000$, $N_c=1000$ und $F_c=0.997$ gewählt.
\begin{figure}[ht]
		\centering
		\includegraphics[height=0.35\textheight]{plot/dummy/dummy.pdf}
		\caption{Ein schmucker Platzhalter}
\end{figure}
\begin{figure}[ht]
		\centering
		\includegraphics[height=0.35\textheight]{plot/dummy/dummy.pdf}
		\caption{Ein schmucker Platzhalter}
\end{figure}
